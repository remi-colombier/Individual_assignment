{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3062be3c",
   "metadata": {},
   "source": [
    "###                                           Statistical Learning individual assignment - RÃ©mi Colombier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f58db",
   "metadata": {},
   "source": [
    "###### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dcfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data from csv\n",
    "data = pd.read_csv(\"C:/Users/rcolombier/OneDrive/Documents/Statistical machine learning/individual assignment/credit_default_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e998c46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cust_id                         0\n",
       "LIMIT_BAL                     202\n",
       "SEX                           161\n",
       "EDUCATION                     199\n",
       "MARRIAGE                      170\n",
       "AGE                           214\n",
       "PAY_0                         195\n",
       "PAY_2                         219\n",
       "PAY_3                         217\n",
       "PAY_4                         199\n",
       "PAY_5                         185\n",
       "PAY_6                         203\n",
       "BILL_AMT1                     185\n",
       "BILL_AMT2                     209\n",
       "BILL_AMT3                     175\n",
       "BILL_AMT4                     165\n",
       "BILL_AMT5                     181\n",
       "BILL_AMT6                     197\n",
       "PAY_AMT1                      204\n",
       "PAY_AMT2                      184\n",
       "PAY_AMT3                      212\n",
       "PAY_AMT4                      197\n",
       "PAY_AMT5                      179\n",
       "PAY_AMT6                      196\n",
       "default.payment.next.month      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262a33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill all the na values in order to run the algorithm\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48b28b",
   "metadata": {},
   "source": [
    "### Run the five algorithms without features selection & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7c7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test set\n",
    "X = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40c4a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize decision tree, logistic, random forest and knn algorithm \n",
    "decision_tree = DecisionTreeClassifier()\n",
    "logistic = LogisticRegression()\n",
    "random_forest = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4237a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"logistic\" : logistic,\n",
    "    \"decision_tree\" : decision_tree,\n",
    "    \"random_forest\": random_forest, \n",
    "    \"knn\": knn \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baf1c273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#fitting the models with the for loop\n",
    "for model in models:\n",
    "    models[model].fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c587d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model in the train set for the 4 algorithms and compute the accuracy score\n",
    "performances_training = {}\n",
    "for model in models:\n",
    "    predictions = models[model].predict(X_train)\n",
    "    probabilities = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    accuracy = accuracy_score(y_train, predictions)\n",
    "    auc = roc_auc_score(y_train, predictions)\n",
    "    performances_training[model] = {\"Accuracy\":accuracy, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a11a177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.777438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.840500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          logistic  decision_tree  random_forest       knn\n",
       "Accuracy  0.777438            1.0            1.0  0.840500\n",
       "AUC       0.500442            1.0            1.0  0.707525"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the training performance of our 4 models\n",
    "pd.DataFrame(performances_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1acdf8",
   "metadata": {},
   "source": [
    "##### Compute the same for test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee954754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model in the test set for the 4 algorithms and compute the accuracy & AUC score\n",
    "performances_testing = {}\n",
    "for model in models:\n",
    "    predictions = models[model].predict(X_test)\n",
    "    probabilities = pd.DataFrame(models[model].predict_proba(X_test))[1]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "    performances_testing[model] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fe822fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.785250</td>\n",
       "      <td>0.724500</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500106</td>\n",
       "      <td>0.617609</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>0.546317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          logistic  decision_tree  random_forest       knn\n",
       "Accuracy  0.785250       0.724500       0.828500  0.728500\n",
       "AUC       0.500106       0.617609       0.665116  0.546317"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the training performance of our 4 models\n",
    "pd.DataFrame(performances_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e173a1",
   "metadata": {},
   "source": [
    "###### Initilialize SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f31a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we define the classifier with the default parameters \n",
    "svc = SVC()\n",
    "\n",
    "#default parameter\n",
    "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state = None, shrinking=True,\n",
    "    tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc6db1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7779375\n"
     ]
    }
   ],
   "source": [
    "#we fit the model with train dataset and we compute accuracy score\n",
    "svc.fit(X_train, y_train)\n",
    "score = svc.score(X_train, y_train)\n",
    "print(\"Accuracy : \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58416a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize svm\n",
    "clf = svm.SVC()\n",
    "\n",
    "#fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a5869f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005622715771718"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute AUC score with train set\n",
    "AUC = metrics.roc_auc_score(y_train, y_pred_train)\n",
    "AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e255e",
   "metadata": {},
   "source": [
    "##### score for test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b963d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.786\n"
     ]
    }
   ],
   "source": [
    "#we fit the model with train dataset and we compute accuracy score\n",
    "svc.fit(X_test, y_test)\n",
    "score = svc.score(X_test, y_test)\n",
    "print(\"Accuracy: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05dcc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict with X_test\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c73ca45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute AUC score with test set\n",
    "AUC = metrics.roc_auc_score(y_test, y_pred_test)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6071f0b",
   "metadata": {},
   "source": [
    "# Feature selection and cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c9c66",
   "metadata": {},
   "source": [
    "## 1) Random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004e4d8",
   "metadata": {},
   "source": [
    "###### 1.1 Features selection Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df63996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.8min finished\n",
      "\n",
      "[2022-03-30 18:57:19] Features: 1/5 -- score: 0.81325[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-03-30 18:58:44] Features: 2/5 -- score: 0.8140000000000001[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.2min finished\n",
      "\n",
      "[2022-03-30 18:59:58] Features: 3/5 -- score: 0.81425[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-03-30 19:01:22] Features: 4/5 -- score: 0.812875[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.4min finished\n",
      "\n",
      "[2022-03-30 19:02:45] Features: 5/5 -- score: 0.8100625000000001"
     ]
    }
   ],
   "source": [
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,\n",
    "           k_features=5,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bf2a8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378bd39",
   "metadata": {},
   "source": [
    "###### 1.2 Cross validation - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "036a1427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a37f5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "random_forest_cv = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab20892a",
   "metadata": {},
   "source": [
    "###### 1.3 fit the model with features selection and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6319fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the values selected above with features selection \n",
    "X_rf= data.iloc[:,[3, 6, 7, 8, 9]].values\n",
    "X_train_rf,X_test_rf,y_train_rf,y_test_rf = train_test_split(X_rf,y,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24995dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "random_forest_cv.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77c50225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model in the train set for logistic regression with feature selection and compute the accuracy score\n",
    "performances_training = {}\n",
    "predictions = random_forest_cv.predict(X_train_rf)\n",
    "probabilities = pd.DataFrame(random_forest_cv.predict_proba(X_train_rf))[1]\n",
    "accuracy = accuracy_score(y_train_rf, predictions)\n",
    "auc = roc_auc_score(y_train_rf, predictions)\n",
    "performances_training[random_forest_cv] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd1bb637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                    n_jobs=-1,\n",
       "                    param_distributions={'bootstrap': [True, False],\n",
       "                                         'max_depth': [10, 20, 30, 40, 50, None],\n",
       "                                         'max_features': ['auto', 'sqrt'],\n",
       "                                         'min_samples_leaf': [1, 2, 4],\n",
       "                                         'min_samples_split': [2, 5, 10],\n",
       "                                         'n_estimators': [200, 400, 600, 800,\n",
       "                                                          1000]},\n",
       "                    random_state=42, verbose=2): {'Accuracy': 0.826625,\n",
       "  'AUC': 0.6550369883463647}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97638372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and test the model in the test set for the logistic regression and compute the accuracy score\n",
    "performances_test = {}\n",
    "predictions = random_forest_cv.predict(X_test_rf)\n",
    "probabilities = pd.DataFrame(random_forest_cv.predict_proba(X_test_rf))[1]\n",
    "accuracy = accuracy_score(y_test_rf, predictions)\n",
    "auc = roc_auc_score(y_test_rf, predictions)\n",
    "performances_test[random_forest_cv] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f138a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                    n_jobs=-1,\n",
       "                    param_distributions={'bootstrap': [True, False],\n",
       "                                         'max_depth': [10, 20, 30, 40, 50, None],\n",
       "                                         'max_features': ['auto', 'sqrt'],\n",
       "                                         'min_samples_leaf': [1, 2, 4],\n",
       "                                         'min_samples_split': [2, 5, 10],\n",
       "                                         'n_estimators': [200, 400, 600, 800,\n",
       "                                                          1000]},\n",
       "                    random_state=42, verbose=2): {'Accuracy': 0.825,\n",
       "  'AUC': 0.665010612384915}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a05d16",
   "metadata": {},
   "source": [
    "# 2) Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8398c",
   "metadata": {},
   "source": [
    "###### 2.1 Features importance - Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8e06543",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b05195c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "820fab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: -0.00003\n",
      "Feature: 1, Score: -0.00000\n",
      "Feature: 2, Score: -0.00000\n",
      "Feature: 3, Score: -0.00000\n",
      "Feature: 4, Score: -0.00000\n",
      "Feature: 5, Score: -0.00003\n",
      "Feature: 6, Score: 0.00001\n",
      "Feature: 7, Score: 0.00000\n",
      "Feature: 8, Score: 0.00000\n",
      "Feature: 9, Score: 0.00000\n",
      "Feature: 10, Score: 0.00000\n",
      "Feature: 11, Score: 0.00000\n",
      "Feature: 12, Score: -0.00001\n",
      "Feature: 13, Score: 0.00000\n",
      "Feature: 14, Score: 0.00000\n",
      "Feature: 15, Score: -0.00000\n",
      "Feature: 16, Score: 0.00000\n",
      "Feature: 17, Score: 0.00000\n",
      "Feature: 18, Score: -0.00003\n",
      "Feature: 19, Score: -0.00003\n",
      "Feature: 20, Score: -0.00001\n",
      "Feature: 21, Score: -0.00002\n",
      "Feature: 22, Score: -0.00001\n",
      "Feature: 23, Score: -0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5238ed5",
   "metadata": {},
   "source": [
    "Here we can see that there is no clear pattern in importances of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9024b1",
   "metadata": {},
   "source": [
    "###### 2.2 Cross validation - Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5c29d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform GridSearchCV to tune best-fit LR model\n",
    "param = {'C': [10**-2,10**-1,10**0,10**1,10**2]}\n",
    "\n",
    "lr_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "gs_model = GridSearchCV(estimator=lr_model, param_grid=param)\n",
    "gs_model.fit(X_train, y_train)\n",
    "\n",
    "# Train a LR model with best parameters\n",
    "model = LogisticRegression(**gs_model.best_params_, penalty='l1', solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccafdf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the best fit parameters compute above to the logistic regression\n",
    "model2 = LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9a88c",
   "metadata": {},
   "source": [
    " ###### 2.3 Fit the logistic model with cross validation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb0e8e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model to the train set\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7dbb9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the test set\n",
    "y_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "025338a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model in the train set for logistic regression with feature selection and compute the accuracy score\n",
    "performances_training = {}\n",
    "predictions = model2.predict(X_train)\n",
    "probabilities = pd.DataFrame(model2.predict_proba(X_train))[1]\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "auc = roc_auc_score(y_train, predictions)\n",
    "performances_training[model2] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e93d999d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{LogisticRegression(C=0.1, penalty='l1', solver='liblinear'): {'Accuracy': 0.804875,\n",
       "  'AUC': 0.5917643549327695}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the new training performance of logistic regression on the train set\n",
    "performances_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08aa8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and test the model in the test set for the logistic regression and compute the accuracy score\n",
    "performances_test = {}\n",
    "predictions = model2.predict(X_test)\n",
    "probabilities = pd.DataFrame(model2.predict_proba(X_test))[1]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "performances_test[model2] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0423ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{LogisticRegression(C=0.1, penalty='l1', solver='liblinear'): {'Accuracy': 0.8225,\n",
       "  'AUC': 0.6146198828238263}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the test performance of logistic regression on the test set\n",
    "performances_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d8a05",
   "metadata": {},
   "source": [
    "We can see that the gap between train and test accuracy is reduce a lot. Then the model is far more accurate than without features selection and cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48173ca5",
   "metadata": {},
   "source": [
    "# 3) Decision tree algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b57aa",
   "metadata": {},
   "source": [
    "###### 3.1     Features importances - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7320586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b62cc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92c584aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bf39bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.09154\n",
      "Feature: 1, Score: 0.04884\n",
      "Feature: 2, Score: 0.01319\n",
      "Feature: 3, Score: 0.02010\n",
      "Feature: 4, Score: 0.01380\n",
      "Feature: 5, Score: 0.05613\n",
      "Feature: 6, Score: 0.15011\n",
      "Feature: 7, Score: 0.03203\n",
      "Feature: 8, Score: 0.00863\n",
      "Feature: 9, Score: 0.01333\n",
      "Feature: 10, Score: 0.00789\n",
      "Feature: 11, Score: 0.01233\n",
      "Feature: 12, Score: 0.06019\n",
      "Feature: 13, Score: 0.04335\n",
      "Feature: 14, Score: 0.03921\n",
      "Feature: 15, Score: 0.04069\n",
      "Feature: 16, Score: 0.04406\n",
      "Feature: 17, Score: 0.04530\n",
      "Feature: 18, Score: 0.03896\n",
      "Feature: 19, Score: 0.05251\n",
      "Feature: 20, Score: 0.03601\n",
      "Feature: 21, Score: 0.04109\n",
      "Feature: 22, Score: 0.04196\n",
      "Feature: 23, Score: 0.04874\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = decision_tree.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531a4d2",
   "metadata": {},
   "source": [
    "Result show that we could take features 0,5,6,12,19 according to the more importance there is to explain Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bfffcc",
   "metadata": {},
   "source": [
    "###### 3.2 Cross validation - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b80f46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do cross validation to select the best parameters for our decision tree algorithm\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e10ef",
   "metadata": {},
   "source": [
    " ###### 3.3 Fit the logistic model with cross validation parameters and features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a5d28ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the values selected above with features importances \n",
    "X_dt= data.iloc[:,[0,5,6,12,19]].values\n",
    "X_train_dt,X_test_dt,y_train_dt,y_test_dt = train_test_split(X_dt,y,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9199d745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...],\n",
       "                         'min_samples_split': [2, 3, 4]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.fit(X_train_dt, y_train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e25dd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf673dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_training = {}\n",
    "predictions = grid_search_cv.predict(X_train_dt)\n",
    "probabilities = pd.DataFrame(grid_search_cv.predict_proba(X_train_dt))[1]\n",
    "accuracy = accuracy_score(y_train_dt, predictions)\n",
    "auc = roc_auc_score(y_train_dt, predictions)\n",
    "performances_training[grid_search_cv] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609c6568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "              param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                             13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                             22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                             31, ...],\n",
       "                          'min_samples_split': [2, 3, 4]},\n",
       "              verbose=1): {'Accuracy': 0.8133125, 'AUC': 0.6327252609261178}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the train results\n",
    "performances_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9be5e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and test the model in the test set for the logistic regression and compute the accuracy score\n",
    "performances_test = {}\n",
    "predictions = grid_search_cv.predict(X_test_dt)\n",
    "probabilities = pd.DataFrame(grid_search_cv.predict_proba(X_test_dt))[1]\n",
    "accuracy = accuracy_score(y_test_dt, predictions)\n",
    "auc = roc_auc_score(y_test_dt, predictions)\n",
    "performances_test[grid_search_cv] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d684dbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "              param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                             13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                             22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                             31, ...],\n",
       "                          'min_samples_split': [2, 3, 4]},\n",
       "              verbose=1): {'Accuracy': 0.83225, 'AUC': 0.6594397135974035}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the test results\n",
    "performances_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f04e99",
   "metadata": {},
   "source": [
    "# 4) K-Nearest neighboursâ algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb168cec",
   "metadata": {},
   "source": [
    "###### 4.1 Cross validation - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8d1555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726   0.72575 0.72525 0.72875 0.72575]\n",
      "cv_scores mean:0.7263000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np#create a new KNN model\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=3)#train model with cv of 5 \n",
    "cv_scores = cross_val_score(knn_cv, X, y, cv=5)#print each cv score (accuracy) and average them\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean:{}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46424e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new a knn model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 25)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2cf347",
   "metadata": {},
   "source": [
    "###### 4.2 Fit the model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1f4010d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model to data\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "19241d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_training = {}\n",
    "predictions = knn_gscv.predict(X_train)\n",
    "probabilities = pd.DataFrame(knn_gscv.predict_proba(X_train))[1]\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "auc = roc_auc_score(y_train, predictions)\n",
    "performances_training[knn_gscv] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1134a969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "              param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24])}): {'Accuracy': 0.7825,\n",
       "  'AUC': 0.5294952743859765}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "52364afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and test the model in the test set for the logistic regression and compute the accuracy score\n",
    "performances_test = {}\n",
    "predictions = knn_gscv.predict(X_test)\n",
    "probabilities = pd.DataFrame(knn_gscv.predict_proba(X_test))[1]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "performances_test[knn_gscv] = {\"Accuracy\":accuracy, \"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fc8e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "              param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24])}): {'Accuracy': 0.78475,\n",
       "  'AUC': 0.522278397550297}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d5db9",
   "metadata": {},
   "source": [
    "# 5) Support Vector Machine Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbaf05",
   "metadata": {},
   "source": [
    "###### 5.1 Cross validation - Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79e5b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n"
     ]
    }
   ],
   "source": [
    "#we define the classifier with the default parameters \n",
    "svc = SVC()\n",
    "print(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e70a641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default parameter\n",
    "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f57011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit support vector machine model\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2778cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV average score: 0.78\n"
     ]
    }
   ],
   "source": [
    "#we can also apply an accuracy score to our train set with 10 fold cross validation\n",
    "\n",
    "cv_scores = cross_val_score(svc, X_train, y_train, cv=10)\n",
    "print(\"CV average score: %.2f\" % cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dfd9ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV average score: 0.79\n"
     ]
    }
   ],
   "source": [
    "#we can also apply an accuracy score to our test set with 10 fold cross validation\n",
    "\n",
    "cv_scores_test = cross_val_score(svc, X_test, y_test, cv=10)\n",
    "print(\"CV average score: %.2f\" % cv_scores_test.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
